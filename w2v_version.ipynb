{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c72698d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in title: 219347\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/train.csv')\n",
    "df = df[df[\"user_id\"].isin([0,1,2,3])]\n",
    "\n",
    "df = pd.read_csv(\"data/item_metadata.csv\")\n",
    "\n",
    "titles = df[\"title\"].dropna()\n",
    "all_words = [word for title in titles for word in title.split()]\n",
    "\n",
    "uqw = set(all_words)\n",
    "print(f\"Number of unique words in title: {len(uqw)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "431ff707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Howard LC0008 Leather Conditioner, 8-Ounce (4-Pack)\n",
      "Yes to Tomatoes Detoxifying Charcoal Cleanser (Pack of 2) with Charcoal Powder, Tomato Fruit Extract, and Gingko Biloba Leaf Extract, 5 fl. oz.\n",
      "Eye Patch Black Adult with Tie Band (6 Per Pack)\n"
     ]
    }
   ],
   "source": [
    "print(titles[0])\n",
    "print(titles[1])\n",
    "print(titles[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb45414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=50000)\n",
    "X = vectorizer.fit_transform(df[\"title\"].fillna(\"\"))\n",
    "print(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "343f76ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using gensim's Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "titles = df[\"title\"].dropna().apply(str.split).tolist()\n",
    "stores = df[\"store\"].dropna().apply(str.split).tolist()\n",
    "description = df[\"description\"].dropna().apply(str.split).tolist()\n",
    "category = df[\"category\"].dropna().apply(str.split).tolist()\n",
    "model = Word2Vec(titles, vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "# Average vectors per title\n",
    "def get_vector(title):\n",
    "    words = title.split()\n",
    "    vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "df[\"title_v\"] = df[\"title\"].fillna(\"\").apply(get_vector)\n",
    "df[\"store_v\"] = df[\"store\"].fillna(\"\").apply(get_vector)\n",
    "df[\"description_v\"] = df[\"description\"].fillna(\"\").apply(get_vector)\n",
    "df[\"category_v\"] = df[\"category\"].fillna(\"\").apply(get_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7de0ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.79477525 -0.09145572 -0.9448379   1.4566729  -1.7657417  -2.0354183\n",
      " -0.2712507   0.40963253  0.6647276  -1.5204257  -1.2012249  -1.5572634\n",
      "  1.3268585  -0.8547957   0.6263747  -2.7810667   2.1434586   0.9227878\n",
      " -0.8290316  -2.7154913  -1.6258346   0.87365144 -2.2809734   0.57719314\n",
      " -2.2244203   1.1003994  -1.2284206  -0.5892255  -4.2885036  -1.7923474\n",
      " -0.24968293 -1.2637568   0.08234332 -0.43256813  0.36135685 -0.9332717\n",
      " -1.530892    0.82903993 -2.8110201   0.5109619   2.171602    1.2829512\n",
      "  0.562826    0.33634365  2.5344708   1.9127059  -3.1565902   0.5226751\n",
      " -0.65061295 -0.01731543  0.01171699  0.09372376  1.4024599  -0.31334814\n",
      " -2.0613742   2.2525854  -0.6618999  -0.10650872 -1.979642    1.3667437\n",
      " -1.3454782   0.17342056  0.49517506  0.8262319  -0.6465023  -0.3157715\n",
      "  0.33003154  2.8523993   1.9423872   1.2163053  -1.7273448   0.84354424\n",
      "  1.9067237   0.2039789   0.6218543  -1.2607628   0.3642694  -1.2623798\n",
      " -0.57700616 -0.03500407  0.7092313   0.5953518  -2.892473    1.04\n",
      " -1.2881534   0.6403452  -1.3553411   0.27383012  0.55120623  1.3118321\n",
      "  2.8398888   0.7637903   0.19202061  4.026563   -1.8135027   0.7971101\n",
      "  1.9690555  -2.5721862  -0.76717603 -0.19552593]\n",
      "Software\n",
      "['All_Beauty' 'Health_and_Personal_Care' 'Software']\n",
      "[('Beauty,', 0.6538078188896179), ('GX', 0.6123785376548767), ('Cosmetics', 0.5755571126937866), ('(A02)', 0.5747848749160767), ('Skincare', 0.5626949071884155), ('Makeover', 0.5605485439300537), ('Wleec', 0.555526077747345), ('Salon:', 0.5551429986953735), ('Pelma', 0.5542073845863342), ('Cosmetic', 0.5399953126907349)]\n"
     ]
    }
   ],
   "source": [
    "inx = 262133 \n",
    "print(df[\"category_v\"][inx])\n",
    "print(df[\"category\"][inx])\n",
    "print(df[\"category\"].unique())\n",
    "\n",
    "sims = model.wv.most_similar('Beauty', topn=10)\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdc051af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['parent_asin', 'main_category', 'title', 'average_rating',\n",
      "       'rating_number', 'price', 'store', 'features', 'description', 'images',\n",
      "       'categories', 'image_count', 'has_images', 'image_urls', 'category',\n",
      "       'title_v', 'store_v', 'description_v', 'category_v'],\n",
      "      dtype='object')\n",
      "[-2.59720296e-01  1.68001652e-01  3.01649243e-01 -1.31225541e-01\n",
      "  1.03785850e-01 -3.74051213e-01 -2.18160093e-01  7.75986671e-01\n",
      " -1.58428267e-01 -1.33072406e-01  1.06063254e-01 -3.73020500e-01\n",
      "  1.26233324e-01  1.44248769e-01  5.96812069e-02  1.52890697e-01\n",
      "  6.05553389e-03 -1.58345491e-01  3.34438193e-03 -2.50568718e-01\n",
      " -1.77389205e-01  2.16671005e-01 -3.77750732e-02  4.12624702e-02\n",
      " -3.69811989e-02 -1.30940095e-01 -3.21436822e-01 -2.10829720e-01\n",
      " -1.67468771e-01  2.91815013e-01  1.90468431e-01 -3.93933982e-01\n",
      " -8.69942382e-02 -2.15910062e-01 -3.56210060e-02 -1.72088921e-01\n",
      " -4.19497222e-01 -3.15286428e-01  1.53820753e-01 -7.16338158e-01\n",
      " -2.55102366e-01 -2.18074280e-03 -1.16263233e-01 -8.10283795e-02\n",
      "  2.46710464e-04 -3.22659522e-01 -6.05138279e-02 -7.65851215e-02\n",
      "  1.17010050e-01 -7.08249956e-03  5.41796029e-01 -1.99088991e-01\n",
      " -2.00905994e-01  1.47701785e-01 -6.09720647e-02  3.72261047e-01\n",
      "  2.22418889e-01 -3.70614290e-01 -1.82210192e-01 -2.19991028e-01\n",
      "  1.17872544e-01  1.96909070e-01  1.95810497e-01 -1.76047921e-01\n",
      "  1.42580271e-03  1.87459234e-02 -4.99167144e-02 -3.93712908e-01\n",
      "  6.67280033e-02  3.46046798e-02 -3.17476064e-01  1.61780313e-01\n",
      "  5.34073770e-01 -4.89799589e-01 -3.64234112e-02  9.79266539e-02\n",
      "  1.36314556e-01  3.46090108e-01 -4.38869923e-01 -9.51505825e-02\n",
      " -1.55568331e-01 -1.72673300e-01 -5.30689776e-01  8.11724439e-02\n",
      " -2.96081513e-01 -2.14432120e-01  2.74367571e-01  3.87443274e-01\n",
      " -1.93588749e-01  4.42534648e-02 -7.70559302e-03  1.31705865e-01\n",
      " -1.01483755e-01 -9.39818844e-03  6.77008152e-01 -7.10274652e-02\n",
      "  2.79116780e-02  8.00860301e-02 -1.84385061e-01 -1.48606226e-01]\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "1-dimensional array given. Array must be at least two-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m val \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle_v\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(val)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdet\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Coding/Python/DSC_task/env/lib/python3.8/site-packages/numpy/linalg/linalg.py:2135\u001b[0m, in \u001b[0;36mdet\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   2087\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2088\u001b[0m \u001b[38;5;124;03mCompute the determinant of an array.\u001b[39;00m\n\u001b[1;32m   2089\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2132\u001b[0m \n\u001b[1;32m   2133\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2134\u001b[0m a \u001b[38;5;241m=\u001b[39m asarray(a)\n\u001b[0;32m-> 2135\u001b[0m \u001b[43m_assert_stacked_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2136\u001b[0m _assert_stacked_square(a)\n\u001b[1;32m   2137\u001b[0m t, result_t \u001b[38;5;241m=\u001b[39m _commonType(a)\n",
      "File \u001b[0;32m~/Coding/Python/DSC_task/env/lib/python3.8/site-packages/numpy/linalg/linalg.py:183\u001b[0m, in \u001b[0;36m_assert_stacked_2d\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 183\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-dimensional array given. Array must be \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    184\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat least two-dimensional\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m a\u001b[38;5;241m.\u001b[39mndim)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: 1-dimensional array given. Array must be at least two-dimensional"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "### KATEGORIE DO WEKTORYZACJI\n",
    "\"\"\"\n",
    "1. main_category\n",
    "2. title\n",
    "3. store\n",
    "5. description\n",
    "6. category\n",
    "\"\"\"\n",
    "#### WYRZUCIĆ\n",
    "\"\"\"\n",
    "0. features   -> narazie zróbmy uproszczoną wersje\n",
    "1. categories -> narazie zróbmy uproszczoną wersje\n",
    "2. image_count\n",
    "3. has_images\n",
    "4. image_urls\n",
    "5. images\n",
    "\"\"\"\n",
    "# print(df.head())\n",
    "val = df[\"title_v\"][0]\n",
    "print(val)\n",
    "print(np.linalg.det(val))\n",
    "print(df[\"category\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b8126a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 19\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# print(df['title'].apply(type))\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# df = np.array(df['title'])\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# object_cols = df.select_dtypes(include='object')\u001b[39;00m\n\u001b[1;32m     17\u001b[0m df_filtered \u001b[38;5;241m=\u001b[39m df[categorical_cols]\n\u001b[0;32m---> 19\u001b[0m cosine_similarity \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_filtered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# cosine_similarity = cosine_similarity(df[categorical_cols])\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(cosine_similarity)\n",
      "File \u001b[0;32m~/Coding/Python/DSC_task/env/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/Coding/Python/DSC_task/env/lib/python3.8/site-packages/sklearn/metrics/pairwise.py:1578\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1544\u001b[0m \n\u001b[1;32m   1545\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1574\u001b[0m \u001b[38;5;124;03m    Returns the cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1575\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[0;32m-> 1578\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1580\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[0;32m~/Coding/Python/DSC_task/env/lib/python3.8/site-packages/sklearn/metrics/pairwise.py:156\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    153\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype_float\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m X \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    166\u001b[0m         X,\n\u001b[1;32m    167\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    172\u001b[0m     )\n",
      "File \u001b[0;32m~/Coding/Python/DSC_task/env/lib/python3.8/site-packages/sklearn/utils/validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 915\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    919\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/Coding/Python/DSC_task/env/lib/python3.8/site-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "high_cardinality_cols = ['parent_asin', 'main_category', 'image_urls', 'images', 'has_images','features', 'categories']\n",
    "\n",
    "categorical_cols = [col for col in df.select_dtypes(include='object').columns\n",
    "                    if col not in high_cardinality_cols]\n",
    "\n",
    "\n",
    "df['title'] = df.apply(np.linalg.det, axis=1)\n",
    "df['store'] = df.apply(np.linalg.det, axis=1)\n",
    "df['description'] = df.apply(np.linalg.det, axis=1)\n",
    "df['category'] = df.apply(np.linalg.det, axis=1)\n",
    "\n",
    "# print(df['title'].apply(type))\n",
    "# df = np.array(df['title'])\n",
    "# object_cols = df.select_dtypes(include='object')\n",
    "df_filtered = df[categorical_cols]\n",
    "\n",
    "cosine_similarity = cosine_similarity(df_filtered)\n",
    "# cosine_similarity = cosine_similarity(df[categorical_cols])\n",
    "print(cosine_similarity)\n",
    "similarity_df = pd.DataFrame(cosine_similarity, index=genre_df.index, columns=genre_df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e5b9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing column: main_category\n",
      "Processing column: title\n",
      "Processing column: store\n",
      "Processing column: description\n",
      "Processing column: category\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# STEP 3: Apply Bag of Words transformation to each categorical column\n",
    "for col in categorical_cols:\n",
    "    try:\n",
    "        vectorizer = CountVectorizer(max_features=1000, stop_words=None)\n",
    "        X = vectorizer.fit_transform(text_data)\n",
    "        bow_df = pd.DataFrame(X.toarray(), columns=[f\"{col}_{feat}\" for feat in vectorizer.get_feature_names_out()])\n",
    "        bow_features.append(bow_df)\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping column '{col}' due to error: {e}\")\n",
    "\n",
    "    # Initialize CountVectorizer\n",
    "    # vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "    # Transform the column into BoW representation\n",
    "    # X_bow = vectorizer.fit_transform(text_data)\n",
    "\n",
    "    # Create a DataFrame from the result with meaningful column names\n",
    "    # bow_df = pd.DataFrame(X_bow.toarray(), columns=[f\"{col}_{feat}\" for feat in vectorizer.get_feature_names_out()])\n",
    "\n",
    "    # bow_features.append(bow_df)\n",
    "\n",
    "# STEP 4: Concatenate all BoW DataFrames horizontally\n",
    "bow_result = pd.concat(bow_features, axis=1)\n",
    "\n",
    "\n",
    "# Optional: Add numerical columns if you want to retain them\n",
    "numerical_cols = df.select_dtypes(include=['number']).reset_index(drop=True)\n",
    "final_df = pd.concat([numerical_cols, bow_result], axis=1)\n",
    "\n",
    "# Show result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef21aec0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfinal_df\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_df' is not defined"
     ]
    }
   ],
   "source": [
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
