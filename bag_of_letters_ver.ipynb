{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c72698d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in title: 219347\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/train.csv')\n",
    "df = df[df[\"user_id\"].isin([0,1,2,3])]\n",
    "\n",
    "df = pd.read_csv(\"data/item_metadata.csv\")\n",
    "\n",
    "titles = df[\"title\"].dropna()\n",
    "all_words = [word for title in titles for word in title.split()]\n",
    "\n",
    "uqw = set(all_words)\n",
    "print(f\"Number of unique words in title: {len(uqw)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "431ff707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Howard LC0008 Leather Conditioner, 8-Ounce (4-Pack)\n",
      "Yes to Tomatoes Detoxifying Charcoal Cleanser (Pack of 2) with Charcoal Powder, Tomato Fruit Extract, and Gingko Biloba Leaf Extract, 5 fl. oz.\n",
      "Eye Patch Black Adult with Tie Band (6 Per Pack)\n"
     ]
    }
   ],
   "source": [
    "print(titles[0])\n",
    "print(titles[1])\n",
    "print(titles[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb45414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=50000)\n",
    "X = vectorizer.fit_transform(df[\"title\"].fillna(\"\"))\n",
    "print(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "343f76ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using gensim's Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "titles = df[\"title\"].dropna().apply(str.split).tolist()\n",
    "stores = df[\"store\"].dropna().apply(str.split).tolist()\n",
    "description = df[\"description\"].dropna().apply(str.split).tolist()\n",
    "category = df[\"category\"].dropna().apply(str.split).tolist()\n",
    "model = Word2Vec(titles, vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "# Average vectors per title\n",
    "def get_vector(title):\n",
    "    words = title.split()\n",
    "    vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "df[\"title\"] = df[\"title\"].fillna(\"\").apply(get_vector)\n",
    "df[\"store\"] = df[\"store\"].fillna(\"\").apply(get_vector)\n",
    "df[\"description\"] = df[\"description\"].fillna(\"\").apply(get_vector)\n",
    "df[\"category\"] = df[\"category\"].fillna(\"\").apply(get_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7de0ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [-0.39734843, 0.22038518, 0.38574108, 0.026300...\n",
      "1    [-0.6260919, 0.27584687, 0.5380544, -0.4122063...\n",
      "2    [0.23102407, 0.2777291, 0.24306421, -0.2691973...\n",
      "3    [-0.8889685, -0.40278447, 0.2526689, -0.497835...\n",
      "4    [-0.2482645, 0.29172987, 1.1735274, -0.3074607...\n",
      "Name: title, dtype: object\n",
      "0         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "1         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "2         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "3         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "4         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "                                ...                        \n",
      "262129    [0.3575052, -0.86605746, -1.1214151, 1.2633457...\n",
      "262130    [0.3575052, -0.86605746, -1.1214151, 1.2633457...\n",
      "262131    [0.3575052, -0.86605746, -1.1214151, 1.2633457...\n",
      "262132    [0.3575052, -0.86605746, -1.1214151, 1.2633457...\n",
      "262133    [0.3575052, -0.86605746, -1.1214151, 1.2633457...\n",
      "Name: category, Length: 262134, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"title\"].head())\n",
    "print(df[\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdc051af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['parent_asin', 'main_category', 'title', 'average_rating',\n",
      "       'rating_number', 'price', 'store', 'features', 'description', 'images',\n",
      "       'categories', 'image_count', 'has_images', 'image_urls', 'category'],\n",
      "      dtype='object')\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "### KATEGORIE DO WEKTORYZACJI\n",
    "\"\"\"\n",
    "1. main_category\n",
    "2. title\n",
    "3. store\n",
    "5. description\n",
    "6. category\n",
    "\"\"\"\n",
    "#### WYRZUCIĆ\n",
    "\"\"\"\n",
    "0. features   -> narazie zróbmy uproszczoną wersje\n",
    "1. categories -> narazie zróbmy uproszczoną wersje\n",
    "2. image_count\n",
    "3. has_images\n",
    "4. image_urls\n",
    "5. images\n",
    "\"\"\"\n",
    "# print(df.head())\n",
    "print(df[\"category\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b8126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "high_cardinality_cols = ['parent_asin', 'image_urls', 'images', 'has_images','features', 'categories']\n",
    "\n",
    "categorical_cols = [col for col in df.select_dtypes(include='object').columns\n",
    "                    if col not in high_cardinality_cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e5b9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing column: main_category\n",
      "Processing column: title\n",
      "Processing column: store\n",
      "Processing column: description\n",
      "Processing column: category\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Apply Bag of Words transformation to each categorical column\n",
    "for col in categorical_cols:\n",
    "    print(f\"Processing column: {col}\")\n",
    "\n",
    "    # Convert categorical values into space-separated string tokens (if needed)\n",
    "    text_data = df[col].fillna(\"\").astype(str)\n",
    "\n",
    "    try:\n",
    "        vectorizer = CountVectorizer(max_features=1000, stop_words=None)\n",
    "        X = vectorizer.fit_transform(text_data)\n",
    "        bow_df = pd.DataFrame(X.toarray(), columns=[f\"{col}_{feat}\" for feat in vectorizer.get_feature_names_out()])\n",
    "        bow_features.append(bow_df)\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping column '{col}' due to error: {e}\")\n",
    "\n",
    "    # Initialize CountVectorizer\n",
    "    # vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "    # Transform the column into BoW representation\n",
    "    # X_bow = vectorizer.fit_transform(text_data)\n",
    "\n",
    "    # Create a DataFrame from the result with meaningful column names\n",
    "    # bow_df = pd.DataFrame(X_bow.toarray(), columns=[f\"{col}_{feat}\" for feat in vectorizer.get_feature_names_out()])\n",
    "\n",
    "    # bow_features.append(bow_df)\n",
    "\n",
    "# STEP 4: Concatenate all BoW DataFrames horizontally\n",
    "bow_result = pd.concat(bow_features, axis=1)\n",
    "\n",
    "\n",
    "# Optional: Add numerical columns if you want to retain them\n",
    "numerical_cols = df.select_dtypes(include=['number']).reset_index(drop=True)\n",
    "final_df = pd.concat([numerical_cols, bow_result], axis=1)\n",
    "\n",
    "# Show result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef21aec0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfinal_df\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_df' is not defined"
     ]
    }
   ],
   "source": [
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
