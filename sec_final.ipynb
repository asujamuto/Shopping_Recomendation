{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6f10d92",
   "metadata": {},
   "source": [
    "### Podstawowe rzeczy\n",
    "\n",
    "1. wprowadzamy sety\n",
    "2. przypisujemy item_id do metadanych\n",
    "3. dodajemy mape złożoną z tablic TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b7c65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed category: All Beauty, TF-IDF shape: (17952, 10000)\n",
      "Processed category: Premium Beauty, TF-IDF shape: (111, 751)\n",
      "Processed category: Health & Personal Care, TF-IDF shape: (10716, 10000)\n",
      "Processed category: Appstore for Android, TF-IDF shape: (43463, 10000)\n",
      "Processed category: Software, TF-IDF shape: (5471, 10000)\n",
      "Processed category: , TF-IDF shape: (113, 4449)\n",
      "Processed category: Gift Cards, TF-IDF shape: (4, 17)\n",
      "Processed category: Computers, TF-IDF shape: (2, 56)\n",
      "Processed category: Home Audio & Theater, TF-IDF shape: (1, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'All Beauty': <17952x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 456065 stored elements in Compressed Sparse Row format>,\n",
       " 'Premium Beauty': <111x751 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 1412 stored elements in Compressed Sparse Row format>,\n",
       " 'Health & Personal Care': <10716x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 303313 stored elements in Compressed Sparse Row format>,\n",
       " 'Appstore for Android': <43463x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 4076735 stored elements in Compressed Sparse Row format>,\n",
       " 'Software': <5471x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 715216 stored elements in Compressed Sparse Row format>,\n",
       " '': <113x4449 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 15271 stored elements in Compressed Sparse Row format>,\n",
       " 'Gift Cards': <4x17 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 60 stored elements in Compressed Sparse Row format>,\n",
       " 'Computers': <2x56 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 100 stored elements in Compressed Sparse Row format>,\n",
       " 'Home Audio & Theater': <1x11 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 11 stored elements in Compressed Sparse Row format>}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "meta_df = pd.read_csv(\"data/item_metadata_filtered.csv\")\n",
    "with open(\"data/id_mappings.json\") as f:\n",
    "    id_map = json.load(f)\n",
    "\n",
    "asin_to_id = {asin: int(item_id) for asin, item_id in id_map[\"item_mapping\"].items()}\n",
    "item_mapping_df = pd.DataFrame(list(asin_to_id.items()), columns=[\"parent_asin\", \"item_id\"])\n",
    "meta_df = pd.merge(meta_df, item_mapping_df, on=\"parent_asin\", how=\"left\")\n",
    "train_df = train_df.merge(meta_df[[\"item_id\", \"main_category\"]], on=\"item_id\", how=\"left\")\n",
    "\n",
    "\n",
    "# Preprocess metadata\n",
    "meta_df[\"title\"] = meta_df[\"title\"].fillna(\"\")\n",
    "meta_df[\"store\"] = meta_df[\"store\"].fillna(\"\")\n",
    "meta_df[\"description\"] = meta_df[\"description\"].fillna(\"\")\n",
    "meta_df[\"average_rating\"] = meta_df[\"average_rating\"].fillna(\"\")\n",
    "meta_df[\"price\"] = meta_df[\"price\"].fillna(\"\")\n",
    "meta_df[\"image_urls\"] = meta_df[\"image_urls\"].fillna(\"[]\")\n",
    "meta_df[\"main_category\"] = meta_df[\"main_category\"].fillna(\"\")\n",
    "\n",
    "# Index by ASIN for lookup\n",
    "meta_df = meta_df.set_index(\"parent_asin\")\n",
    "\n",
    "# --- TF-IDF ---\n",
    "tfidf_matrix_dictionary = {}\n",
    "for category in meta_df[\"main_category\"].unique():\n",
    "    # Filter ASINs for current category\n",
    "    category_df = meta_df[meta_df[\"main_category\"] == category]\n",
    "    \n",
    "    texts = [\n",
    "        row[\"title\"] + \" \" + row[\"store\"] + \" \" + row[\"description\"]\n",
    "        for _, row in category_df.iterrows()\n",
    "    ]\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(max_features=10000)\n",
    "    tfidf_matrix_dictionary[category] = vectorizer.fit_transform(texts)\n",
    "    \n",
    "    print(f\"Processed category: {category}, TF-IDF shape: {tfidf_matrix_dictionary[category].shape}\")\n",
    "tfidf_matrix_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "382eadfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df = {}\n",
    "for category in meta_df[\"main_category\"].unique():\n",
    "    category_df[category] = meta_df[meta_df[\"main_category\"] == category]\n",
    "    category_df[category].drop(columns=\"main_category\", axis=1)\n",
    "    \n",
    "category_df[\"All Beauty\"].head()\n",
    "item_id_to_index_dictionary = {\n",
    "    category: {\n",
    "        item_id: idx for idx, item_id in enumerate(df[\"item_id\"].values)\n",
    "    }\n",
    "    for category, df in category_df.items()\n",
    "    }\n",
    "index_to_item_id_dictionary = {\n",
    "    category: {v: k for k, v in item_id_to_index_dictionary[category].items()}\n",
    "    for category in item_id_to_index_dictionary\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d6cb5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_user_profile(user_id):\n",
    "    try:\n",
    "        user_ratings = train_df[train_df[\"user_id\"] == user_id]\n",
    "        categories = user_ratings[\"main_category\"].unique()\n",
    "\n",
    "        profile_parts = []\n",
    "        tfidf_vectors = None\n",
    "        for category in categories:\n",
    "            category_ratings = user_ratings[user_ratings[\"main_category\"] == category]\n",
    "            item_ids = category_ratings[\"item_id\"].values\n",
    "            ratings = category_ratings[\"rating\"].values\n",
    "\n",
    "            # Mapping: item_id -> index in TF-IDF matrix\n",
    "            id_to_index = item_id_to_index_dictionary.get(category, {})\n",
    "            indices = [id_to_index[item_id] for item_id in item_ids if item_id in id_to_index]\n",
    "            filtered_ratings = [r for item_id, r in zip(item_ids, ratings) if item_id in id_to_index]\n",
    "\n",
    "            if not indices:\n",
    "                continue\n",
    "\n",
    "            tfidf_vectors = tfidf_matrix_dictionary[category][indices]\n",
    "            weighted = tfidf_vectors.multiply(np.array(filtered_ratings)[:, None])\n",
    "\n",
    "            # Ensure weighted.mean(axis=0) is converted to a dense 1D array\n",
    "            mean_vector = weighted.mean(axis=0)\n",
    "            if hasattr(mean_vector, \"toarray\"):\n",
    "                mean_vector = mean_vector.toarray().ravel()  # Convert sparse matrix to flat array\n",
    "            else:\n",
    "                mean_vector = np.asarray(mean_vector).ravel()\n",
    "\n",
    "            profile_parts.append(mean_vector)\n",
    "\n",
    "        if not profile_parts:\n",
    "            return None  # or np.zeros(shape) if you prefer to return a default profile\n",
    "\n",
    "        # Safely average dense 1D vectors\n",
    "        profile = np.mean(profile_parts, axis=0)\n",
    "        return profile, tfidf_vectors \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Wyszło dla user o id: \", user_id)\n",
    "\n",
    "\n",
    "def recommend_for_user(user_id, top_k=10):\n",
    "    user_items = train_df[train_df[\"user_id\"] == user_id][\"item_id\"]\n",
    "    categories = meta_df[meta_df[\"item_id\"].isin(user_items)][\"main_category\"].unique()\n",
    "    \n",
    "    profile_parts = []\n",
    "    all_vectors = []\n",
    "    all_indices = []\n",
    "    seen_items = set(train_df.loc[train_df[\"user_id\"] == user_id, \"item_id\"])\n",
    "    \n",
    "    for category in categories:\n",
    "        user_ratings = train_df[(train_df[\"user_id\"] == user_id) & (train_df[\"main_category\"] == category)]\n",
    "        item_ids = user_ratings[\"item_id\"].values\n",
    "        ratings = user_ratings[\"rating\"].values\n",
    "        \n",
    "        id_to_index = item_id_to_index_dictionary.get(category, {})\n",
    "        indices = [id_to_index[item_id] for item_id in item_ids if item_id in id_to_index]\n",
    "        filtered_ratings = [r for item_id, r in zip(item_ids, ratings) if item_id in id_to_index]\n",
    "        \n",
    "        if not indices:\n",
    "            continue\n",
    "        \n",
    "        tfidf_vectors = tfidf_matrix_dictionary[category][indices]\n",
    "        weighted = tfidf_vectors.multiply(np.array(filtered_ratings)[:, None])\n",
    "        profile_parts.append(weighted.mean(axis=0))\n",
    "    \n",
    "    if not profile_parts:\n",
    "        return \"\"\n",
    "        \n",
    "    try:\n",
    "        profile = np.mean(profile_parts, axis=0)\n",
    "    except Exception as e: \n",
    "        print(f\"user id: {user_id}\")\n",
    "        raise Exception(e)\n",
    "    \n",
    "    # Try to find recommendations from user's categories first\n",
    "    recommendations = []\n",
    "    for category in categories:\n",
    "        tfidf_matrix = tfidf_matrix_dictionary.get(category)\n",
    "        index_to_item_id = index_to_item_id_dictionary.get(category)\n",
    "        scores = cosine_similarity(profile, tfidf_matrix).ravel()\n",
    "        \n",
    "        ranked_indices = np.argsort(-scores)\n",
    "        recs = [index_to_item_id[i] for i in ranked_indices if index_to_item_id[i] not in seen_items]\n",
    "        recommendations.extend(recs)\n",
    "        \n",
    "        if len(recommendations) >= top_k:\n",
    "            return ' '.join(map(str, recommendations[:top_k]))\n",
    "    \n",
    "    # Fallback: try other categories if needed\n",
    "    other_categories = [cat for cat in tfidf_matrix_dictionary.keys() if cat not in categories]\n",
    "    for category in other_categories:\n",
    "        tfidf_matrix = tfidf_matrix_dictionary.get(category)\n",
    "        index_to_item_id = index_to_item_id_dictionary.get(category)\n",
    "        scores = cosine_similarity(profile, tfidf_matrix).ravel()\n",
    "\n",
    "        ranked_indices = np.argsort(-scores)\n",
    "        recs = [index_to_item_id[i] for i in ranked_indices if index_to_item_id[i] not in seen_items]\n",
    "        recommendations.extend(recs)\n",
    "\n",
    "        if len(recommendations) >= top_k:\n",
    "            break\n",
    "\n",
    "    return ' '.join(map(str, recommendations[:top_k]))\n",
    "\n",
    "\n",
    "def solve_and_save(min, max, num):\n",
    "    df_final = pd.DataFrame({\n",
    "            \"user_id\": train_df[\"user_id\"].unique()[min:max],\n",
    "    })\n",
    "        # df_final[\"predictions\"] = df_final[\"user_id\"].apply(recommend_for_user, args=(train_df[\"main_category\"]))\n",
    "    df_final[\"predictions\"] = df_final[\"user_id\"].apply(\n",
    "            lambda user_id: recommend_for_user(user_id)\n",
    "    )\n",
    "\n",
    "    name = f\"user_predictions{num}.csv\"\n",
    "    print(name, flush=True)\n",
    "    df_final.to_csv(name, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19fa8d6",
   "metadata": {},
   "source": [
    "## Dziwny problem z tym rekordem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2308e152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>main_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>639</td>\n",
       "      <td>75774</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1659731231155</td>\n",
       "      <td>Premium Beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>639</td>\n",
       "      <td>47417</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1677127171442</td>\n",
       "      <td>All Beauty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  item_id  rating      timestamp   main_category\n",
       "1930      639    75774     3.0  1659731231155  Premium Beauty\n",
       "1931      639    47417     5.0  1677127171442      All Beauty"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"user_id\"] == 639]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfaf6cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user id: 639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pete/Coding/Python/DSC_task/env/lib/python3.6/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "could not broadcast input array from shape (751) into shape (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-014f72dc6f73>\u001b[0m in \u001b[0;36mrecommend_for_user\u001b[0;34m(user_id, top_k)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mprofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Coding/Python/DSC_task/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3372\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 3373\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   3374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coding/Python/DSC_task/env/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coding/Python/DSC_task/env/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \"\"\"\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (751) into shape (1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-295548f86b50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msolve_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-014f72dc6f73>\u001b[0m in \u001b[0;36msolve_and_save\u001b[0;34m(min, max, num)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# df_final[\"predictions\"] = df_final[\"user_id\"].apply(recommend_for_user, args=(train_df[\"main_category\"]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     df_final[\"predictions\"] = df_final[\"user_id\"].apply(\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mlambda\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrecommend_for_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coding/Python/DSC_task/env/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4212\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4213\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-014f72dc6f73>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(user_id)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# df_final[\"predictions\"] = df_final[\"user_id\"].apply(recommend_for_user, args=(train_df[\"main_category\"]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     df_final[\"predictions\"] = df_final[\"user_id\"].apply(\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mlambda\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrecommend_for_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-014f72dc6f73>\u001b[0m in \u001b[0;36mrecommend_for_user\u001b[0;34m(user_id, top_k)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"user id: {user_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# Try to find recommendations from user's categories first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: could not broadcast input array from shape (751) into shape (1)"
     ]
    }
   ],
   "source": [
    "solve_and_save(0, 20000, 20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb61d6f0",
   "metadata": {},
   "source": [
    "### Tutaj poniżej kiedy będzie wszystko działać"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e555c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukończono plik o numerze: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 73.08it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pete/Coding/Python/DSC_task/env/lib/python3.6/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-8-2b7580ec1215>\", line 135, in solve_and_save\n",
      "    lambda user_id: recommend_for_user(user_id)\n",
      "  File \"/home/pete/Coding/Python/DSC_task/env/lib/python3.6/site-packages/pandas/core/series.py\", line 4213, in apply\n",
      "    mapped = lib.map_infer(values, f, convert=convert_dtype)\n",
      "  File \"pandas/_libs/lib.pyx\", line 2403, in pandas._libs.lib.map_infer\n",
      "  File \"<ipython-input-8-2b7580ec1215>\", line 135, in <lambda>\n",
      "    lambda user_id: recommend_for_user(user_id)\n",
      "  File \"<ipython-input-8-2b7580ec1215>\", line 95, in recommend_for_user\n",
      "    profile = np.mean(profile_parts, axis=0)\n",
      "  File \"<__array_function__ internals>\", line 6, in mean\n",
      "  File \"/home/pete/Coding/Python/DSC_task/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py\", line 3373, in mean\n",
      "    out=out, **kwargs)\n",
      "  File \"/home/pete/Coding/Python/DSC_task/env/lib/python3.6/site-packages/numpy/core/_methods.py\", line 144, in _mean\n",
      "    arr = asanyarray(a)\n",
      "  File \"/home/pete/Coding/Python/DSC_task/env/lib/python3.6/site-packages/numpy/core/_asarray.py\", line 136, in asanyarray\n",
      "    return array(a, dtype, copy=False, order=order, subok=True)\n",
      "ValueError: could not broadcast input array from shape (751) into shape (1)\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "processes = []\n",
    "for i, min_idx in tqdm(enumerate(range(0, 20000, 20000))):\n",
    "    max_idx = min(min_idx + 20000, 868218)\n",
    "    p = Process(target=solve_and_save, args=(min_idx, max_idx, i))\n",
    "    processes.append(p)\n",
    "    print(f\"Ukończono plik o numerze: {i}\")\n",
    "    p.start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
